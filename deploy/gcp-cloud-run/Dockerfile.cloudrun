# Scentier AI Platform - Cloud Run Optimized Dockerfile
# v0.8.2-rc1

# =============================================================================
# Stage 1: Build Stage
# =============================================================================
FROM node:20-alpine AS builder

# Install build dependencies
RUN apk add --no-cache python3 py3-pip

WORKDIR /app

# Copy package files first for layer caching
COPY package.json package-lock.json ./
COPY api/package.json ./api/package.json
COPY client/package.json ./client/package.json
COPY packages/data-provider/package.json ./packages/data-provider/package.json
COPY packages/data-schemas/package.json ./packages/data-schemas/package.json
COPY packages/api/package.json ./packages/api/package.json

# Configure npm for reliability
RUN npm config set fetch-retry-maxtimeout 600000 && \
    npm config set fetch-retries 5 && \
    npm config set fetch-retry-mintimeout 15000

# Install all dependencies
RUN npm ci --no-audit

# Copy source code
COPY . .

# Build frontend and packages
RUN NODE_OPTIONS="--max-old-space-size=2048" npm run frontend

# Prune dev dependencies
RUN npm prune --production && \
    npm cache clean --force

# =============================================================================
# Stage 2: Production Runtime
# =============================================================================
FROM node:20-alpine AS runtime

# Install runtime dependencies
# - jemalloc: Memory optimization
# - python3, uv: Required for MCP server support
# - tini: Proper init process for containers
RUN apk add --no-cache \
    jemalloc \
    python3 \
    py3-pip \
    tini \
    curl

# Add uv for extended MCP support
COPY --from=ghcr.io/astral-sh/uv:0.9.5-python3.12-alpine /usr/local/bin/uv /usr/local/bin/uvx /bin/

# jemalloc disabled: may interfere with Node.js Undici HTTP client (MCP connections)
# ENV LD_PRELOAD=/usr/lib/libjemalloc.so.2

# Create app directory
RUN mkdir -p /app && chown node:node /app
WORKDIR /app

# Copy built application from builder
COPY --from=builder --chown=node:node /app/package.json /app/package-lock.json ./
COPY --from=builder --chown=node:node /app/node_modules ./node_modules
COPY --from=builder --chown=node:node /app/api ./api
COPY --from=builder --chown=node:node /app/client/dist ./client/dist
COPY --from=builder --chown=node:node /app/packages ./packages
COPY --from=builder --chown=node:node /app/config ./config
# Note: librechat.yaml is provided via Secret Manager volume mount in Cloud Run
# (CONFIG_PATH=/secrets/config/librechat.yaml)

# Create necessary directories (Cloud Run uses in-memory storage)
RUN mkdir -p /app/client/public/images /app/logs /app/uploads && \
    chown -R node:node /app/client/public/images /app/logs /app/uploads

# Switch to non-root user
USER node

# Cloud Run Configuration
# -----------------------
# PORT is automatically set by Cloud Run
# HOST must be 0.0.0.0 to accept external connections

ENV NODE_ENV=production
ENV HOST=0.0.0.0
# Prefer IPv4 for DNS resolution (Cloud Run compatibility)
ENV NODE_OPTIONS="--dns-result-order=ipv4first"

# Cloud Run uses PORT environment variable (default 8080)
# The application reads PORT from environment
ENV PORT=8080

# Enable JSON logging for Cloud Logging integration
ENV CONSOLE_JSON=true

# Health check for Cloud Run
HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
    CMD curl -f http://localhost:${PORT}/api/health || exit 1

# Expose the port (Cloud Run uses PORT env var)
EXPOSE 8080

# Use tini as init process
ENTRYPOINT ["/sbin/tini", "--"]

# Start the application
CMD ["npm", "run", "backend"]
